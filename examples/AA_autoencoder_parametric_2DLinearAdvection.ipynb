{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d04dff5",
   "metadata": {},
   "source": [
    "## Notebook to train an Advection-Aware AutoEncoder for a parametric 2D Linear Advection example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96376f86",
   "metadata": {},
   "source": [
    "Consider the advection of a circular Gaussian pulse traveling in the positive $y-$direction through a rectangular domain, $\\Omega = [-100,100] \\times [0, 500]$ at a constant speed, $c$. The analytical solution is given by\n",
    "\\begin{align}\\label{eq:Gaussian_pulse}\n",
    "    u(x,y) = \\exp{ \\bigg\\{ -\\left(\\frac{(x -x_0)^2}{2 \\sigma_x^2} + \\frac{(y - y_0 - ct)^2}{2 \\sigma_y^2} \\right) \\bigg\\} },\n",
    "\\end{align}\n",
    "where $(x_0, y_0)$ is the initial location of the center of the pulse, $\\sigma_x$ and $\\sigma_y$ define the support of the pulse in the $x$ and $y$ directions, respectively. The domain is uniformly discretized into $100701$ computational nodes using $\\Delta x = 1$ and $\\Delta y = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77f002",
   "metadata": {},
   "source": [
    "#### Discussion \n",
    "1. Both decoders train well with pulses of larger support (>= 10)\n",
    "2. The difference between shift prediction and reconstruction becomes significant with sigma = 5 and lower when using RMSE loss function.\n",
    "3. Using the Rel RMSE loss function does not alter the trend significantly.\n",
    "4. Using Max Absolute error makes things worse and widens the training gap between shift and reconstruction error.\n",
    "5. Using swish activation function improves the error for sigma = 5 and sigma = 2.5.\n",
    "6. SeriesEncoder model with both losses only trains the shift decoder and not the NN map following it. But if the shift decoder is not included in the loss then the NN map trains well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923835cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T18:14:35.852490Z",
     "start_time": "2021-08-06T18:14:35.840463Z"
    }
   },
   "source": [
    "### Observations\n",
    "1. Scaling data seems to have a measurable impact on accuracy. Scaling the parameter value separately from the snapshot data helps training. \n",
    "2. Augmenting input vector with parameter value (support size or speed) offers marginal benefit.\n",
    "3. Lower batch size helps training.\n",
    "3. Increasing the size of the latent space leads to better reconstruction. In general, autoencoders tend to fail reconstructing high-frequent noise (i.e. sudden, big changes across few pixels) due to the choice of MSE as loss function (see our previous discussion about loss functions in autoencoders). Small misalignments in the decoder can lead to huge losses so that the model settles for the expected value/mean in these regions. For low-frequent noise, a misalignment of a few pixels does not result in a big difference to the original image. However, the larger the latent dimensionality becomes, the more of this high-frequent noise can be accurately reconstructed.\n",
    "\n",
    "See https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial9/AE_CIFAR10.html\n",
    "\n",
    "Compare reconstruction error over latent dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea02c91c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:24:36.633583Z",
     "start_time": "2022-02-14T03:24:12.745748Z"
    },
    "code_folding": [
     0,
     51
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow v2.4.2\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "## Load modules\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import importlib\n",
    "from importlib import reload as reload\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow v\"+str(tf.__version__))\n",
    "if tf.__version__ == '1.15.0':\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "elif tf.__version__.split('.')[0] == 2: # in ['2.2.0','2.3.0']:\n",
    "    print(\"Setting Keras backend datatype\")\n",
    "    tf.keras.backend.set_floatx('float32')\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "# tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, ScalarFormatter, FormatStrFormatter\n",
    "\n",
    "from matplotlib import animation\n",
    "matplotlib.rc('animation', html='html5')\n",
    "from IPython.display import display\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "\n",
    "# Plot parameters\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams.update({'font.size': 20,\n",
    "                     'lines.linewidth': 2,\n",
    "                     'lines.markersize':10,\n",
    "                     'axes.labelsize': 16, # fontsize for x and y labels (was 10)\n",
    "                     'axes.titlesize': 20,\n",
    "                     'xtick.labelsize': 16,\n",
    "                     'ytick.labelsize': 16,\n",
    "                     'legend.fontsize': 16,\n",
    "                     'axes.linewidth': 2})\n",
    "\n",
    "import itertools\n",
    "colors = itertools.cycle(['r','g','b','m','y','c'])\n",
    "markers = itertools.cycle(['p','d','o','^','s','x','D','H','v','*'])\n",
    "\n",
    "try:\n",
    "    os.listdir(base_dir)\n",
    "except:\n",
    "    base_dir = os.getcwd()\n",
    "utils_dir  = os.path.join(base_dir,'../src/utils')\n",
    "nn_dir  = os.path.join(base_dir,'../src/nn_model')\n",
    "work_dir = os.path.join(base_dir,'../examples')\n",
    "# data_dir = '/gpfs/cwfs/sdutta/hfm_data/Pulse/'  #\n",
    "data_dir = os.path.join(base_dir,'../data/')\n",
    "model_dir = os.path.join(base_dir,'../data/saved_models/')\n",
    "fig_dir  = os.path.join(base_dir,'../figures/')\n",
    "\n",
    "\n",
    "os.chdir(utils_dir)\n",
    "import data_utils as du\n",
    "import tf_utils as tu\n",
    "import plot_utils as pu\n",
    "\n",
    "os.chdir(nn_dir)\n",
    "import aa_autoencoder as aa\n",
    "reload(aa)\n",
    "os.chdir(work_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed3036f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:39:53.156484Z",
     "start_time": "2022-02-14T03:39:53.153905Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'gpu:0' # select gpu:# or cpu:#\n",
    "epochs_u = 6000\n",
    "\n",
    "## Uncomment the following when training for variable pulse size\n",
    "param_list = [ 5, 10, 20]; flag = 'sigma';  # pulse geometry as a parameter\n",
    "\n",
    "## Uncomment the following when training for variable pulse speed\n",
    "# param_list = [1, 2, 3, 4]; flag = 'speed';    # pulse speed as a parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc353ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:39:57.906049Z",
     "start_time": "2022-02-14T03:39:53.841887Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: Loading snapshots for c = 1.000000, sigma = 5.000000\n",
      "Loaded 451 snapshots of dimension 100701 for ['pulse']  spanning times [0.000, 7.500] mins\n",
      "\n",
      "1: Loading snapshots for c = 1.000000, sigma = 10.000000\n",
      "Loaded 451 snapshots of dimension 100701 for ['pulse']  spanning times [0.000, 7.500] mins\n",
      "\n",
      "2: Loading snapshots for c = 1.000000, sigma = 20.000000\n",
      "Loaded 451 snapshots of dimension 100701 for ['pulse']  spanning times [0.000, 7.500] mins\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load snapshot data\n",
    "model ='Pulse'\n",
    "soln_names = ['pulse']\n",
    "\n",
    "snap_data = {}; times_offline = {}\n",
    "c = {}; sigma = {}\n",
    "snap_start = {}; snap_end = {}\n",
    "\n",
    "for indx,val in enumerate(param_list):\n",
    "    if flag == 'sigma':\n",
    "        datafile = 'Gaussian2d_pulse_500x200_c1.00_sigma'+'%.4f'%val+'.npz'\n",
    "    elif flag == 'speed':\n",
    "        datafile = 'Gaussian2d_pulse_500x200_c'+'%.2f'%val+'_sigma5.0000.npz'\n",
    "    data = np.load(os.path.join(data_dir, datafile))\n",
    "    \n",
    "    c[indx] = float(datafile.split('_c')[1].split('_')[0])\n",
    "    sigma[indx] = float(datafile.split('_sigma')[1].split('.npz')[0])\n",
    "    print(\"\\n%d: Loading snapshots for c = %f, sigma = %f\"%(indx, c[indx], sigma[indx]))\n",
    "    \n",
    "    snap_data[indx], times_offline[indx], nodes, Nx, Ny, snap_start[indx], snap_end[indx] = du.read_data(data, soln_names)\n",
    "    \n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f077cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:01.374306Z",
     "start_time": "2022-02-14T03:40:01.363944Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Augment input snapshots for higher speed pulse systems\n",
    "\n",
    "ctr = len(snap_data.keys())\n",
    "\n",
    "for param in param_list:\n",
    "    if param == 2:\n",
    "        for indx,val in enumerate([41,]):\n",
    "            datafile = 'gaussian2d_pulse_500x200_c%.2f_sigma5.0000_y0%d.npz'%(param,val)\n",
    "            data = np.load(os.path.join(data_dir, datafile))\n",
    "\n",
    "            c[ctr] = float(datafile.split('_c')[1].split('_')[0])\n",
    "            sigma[ctr] = float(datafile.split('_sigma')[1].split('_y0')[0])\n",
    "            print(\"\\n%d: Loading snapshots for c = %f, sigma = %f\"%(ctr, c[ctr], sigma[ctr]))\n",
    "            snap_data[ctr], times_offline[ctr], nodes, Nx, Ny, \\\n",
    "                    snap_start[ctr], snap_end[ctr] = du.read_data(data, soln_names)\n",
    "            ctr +=1\n",
    "            \n",
    "        del data\n",
    "        gc.collect()\n",
    "    \n",
    "    elif param == 3:\n",
    "        for indx,val in enumerate([41,42,]):\n",
    "            datafile = 'gaussian2d_pulse_500x200_c%.2f_sigma5.0000_y0%d.npz'%(param,val)\n",
    "            data = np.load(os.path.join(data_dir, datafile))\n",
    "\n",
    "            c[ctr] = float(datafile.split('_c')[1].split('_')[0])\n",
    "            sigma[ctr] = float(datafile.split('_sigma')[1].split('_y0')[0])\n",
    "            print(\"\\n%d: Loading snapshots for c = %f, sigma = %f\"%(ctr, c[ctr], sigma[ctr]))\n",
    "            snap_data[ctr], times_offline[ctr], nodes, Nx, Ny, \\\n",
    "                    snap_start[ctr], snap_end[ctr] = du.read_data(data, soln_names)\n",
    "            ctr +=1\n",
    "            \n",
    "        del data\n",
    "        gc.collect()\n",
    "\n",
    "    elif param == 4:\n",
    "        for indx,val in enumerate([41,42,43]):\n",
    "            datafile = 'gaussian2d_pulse_500x200_c%.2f_sigma5.0000_y0%d.npz'%(param,val)\n",
    "            data = np.load(os.path.join(data_dir, datafile))\n",
    "\n",
    "            c[ctr] = float(datafile.split('_c')[1].split('_')[0])\n",
    "            sigma[ctr] = float(datafile.split('_sigma')[1].split('_y0')[0])\n",
    "            print(\"\\n%d: Loading snapshots for c = %f, sigma = %f\"%(ctr, c[ctr], sigma[ctr]))\n",
    "            snap_data[ctr], times_offline[ctr], nodes, Nx, Ny, \\\n",
    "                    snap_start[ctr], snap_end[ctr] = du.read_data(data, soln_names)\n",
    "            ctr +=1\n",
    "            \n",
    "        del data\n",
    "        gc.collect()\n",
    "    \n",
    "    \n",
    "if flag == 'speed':\n",
    "    param_list = list(c.values())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc4f26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:04.201305Z",
     "start_time": "2022-02-14T03:40:04.195767Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Using 226 training snapshots for sigma = 5.00 in time interval [0.00,7.50] mins\n",
      "1: Using 226 training snapshots for sigma = 10.00 in time interval [0.00,7.50] mins\n",
      "2: Using 226 training snapshots for sigma = 20.00 in time interval [0.00,7.50] mins\n"
     ]
    }
   ],
   "source": [
    "## Prepare training snapshots\n",
    "\n",
    "Nn = Nx * Ny\n",
    "\n",
    "## number of steps to skip in selecting training snapshots for SVD basis\n",
    "snap_incr=2\n",
    "\n",
    "## Subsample snapshots for building reduced basis\n",
    "Nt = {}\n",
    "Nt_train = {}\n",
    "for indx,val in enumerate(param_list):\n",
    "    Nt[indx] = times_offline[indx].size\n",
    "    Nt_train[indx] = times_offline[indx][:snap_end[indx]+1:snap_incr].size\n",
    "    print('{5}: Using {0} training snapshots for {1} = {2:.2f} in time interval [{3:.2f},{4:.2f}] mins'.format(\n",
    "                            Nt_train[indx], flag, param_list[indx], times_offline[indx][:snap_end[indx]+1:snap_incr][0]/60, \n",
    "                            times_offline[indx][:snap_end[indx]+1:snap_incr][-1]/60, indx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb1588c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:05.941667Z",
     "start_time": "2022-02-14T03:40:05.938891Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def set_label(key):\n",
    "    if key == 'pulse':\n",
    "        ky = 'u'\n",
    "    \n",
    "    return ky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3129ec6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:08.116802Z",
     "start_time": "2022-02-14T03:40:07.399164Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading high-fidelity shifted snapshots -----\n",
      "\n",
      "\n",
      "Reading data from Shift_Gaussian2d_pulse_500x200_c1.00_sigma5.0000.npz\n",
      "0: Loading 451 shifted snapshots for c = 1.000000, sigma = 5.000000, key = pulse\n",
      "\n",
      "Reading data from Shift_Gaussian2d_pulse_500x200_c1.00_sigma10.0000.npz\n",
      "1: Loading 451 shifted snapshots for c = 1.000000, sigma = 10.000000, key = pulse\n",
      "\n",
      "Reading data from Shift_Gaussian2d_pulse_500x200_c1.00_sigma20.0000.npz\n",
      "2: Loading 451 shifted snapshots for c = 1.000000, sigma = 20.000000, key = pulse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load shifted snapshots   \n",
    "print(\"Loading high-fidelity shifted snapshots -----\\n\")\n",
    "\n",
    "shifted_snap = {}\n",
    "for indx,val in enumerate(param_list):\n",
    "    if flag == 'sigma':\n",
    "        shift_datafile = 'Shift_Gaussian2d_pulse_500x200_c1.00_sigma'+'%.4f'%val+'.npz'\n",
    "    elif flag == 'speed':\n",
    "        shift_datafile = 'Shift_Gaussian2d_pulse_500x200_c'+'%.2f'%val+'_sigma5.0000.npz'\n",
    "    \n",
    "    print(\"\\nReading data from %s\"%shift_datafile)\n",
    "    shift_data = np.load(os.path.join(data_dir, shift_datafile))\n",
    "    shifted_snap[indx] = {}\n",
    "    for key in soln_names:\n",
    "        shifted_snap[indx][key] = np.outer(shift_data[key].reshape((Nn,-1)),np.ones(Nt[indx]))\n",
    "\n",
    "        print(\"%d: Loading %d shifted snapshots for c = %f, sigma = %f, key = %s\"%(indx, \n",
    "                                                            shifted_snap[indx][key].shape[1], \n",
    "                                                            c[indx], sigma[indx], key))\n",
    "        \n",
    "del shift_data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f1446c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:14.724332Z",
     "start_time": "2022-02-14T03:40:08.969187Z"
    }
   },
   "outputs": [],
   "source": [
    "###  ***** Prepare Autoencoder input data *******\n",
    "## 1. Concatenate parametric snapshots to prepare\n",
    "##    input features for AA Autoencoder training\n",
    "\n",
    "u = np.empty((0,Nn),)\n",
    "u_shift = np.empty((0,Nn),)\n",
    "\n",
    "p_max = np.asarray(param_list).max()\n",
    "for indx,val in enumerate(param_list):\n",
    "    u_snap = snap_data[indx]['pulse'][:,:snap_end[indx]+1:snap_incr].T    \n",
    "    u = np.vstack((u,u_snap))\n",
    "    u_shift_snap = shifted_snap[indx]['pulse'][:,:snap_end[indx]+1:snap_incr].T\n",
    "    u_shift = np.vstack((u_shift,u_shift_snap))\n",
    "    \n",
    "\n",
    "validation_data = True\n",
    "skip_start = snap_incr//2\n",
    "if validation_data:\n",
    "    u_val = np.empty((0,Nn),)\n",
    "    u_val_shift = np.empty((0,Nn),)\n",
    "    for indx,val in enumerate(param_list):\n",
    "        u_val_snap = snap_data[indx]['pulse'][:,skip_start:snap_end[indx]+1:snap_incr].T\n",
    "        u_val_shift_snap = shifted_snap[indx]['pulse'][:,skip_start:snap_end[indx]+1:snap_incr].T\n",
    "        u_val = np.vstack((u_val, u_val_snap))\n",
    "        u_val_shift = np.vstack((u_val_shift, u_val_shift_snap))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d319e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:16.675818Z",
     "start_time": "2022-02-14T03:40:14.726061Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Scale Input Features to lie between [0,1]\n",
    "\n",
    "scaling=True\n",
    "\n",
    "if scaling:\n",
    "    u, u_shift, u_max, u_min = du.data_scaler(u, u_shift)\n",
    "\n",
    "    if validation_data:\n",
    "        u_val, u_val_shift, _, _ = du.data_scaler(u_val, u_val_shift, u_max, u_min)\n",
    "        \n",
    "else:\n",
    "    u_max = np.maximum(u.max(), u_shift.max()); u_min = np.minimum(u.min(), u_shift.min())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d2393e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:18.147933Z",
     "start_time": "2022-02-14T03:40:16.678442Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "###  ***** Prepare Autoencoder input data *******\n",
    "## 2. Augment input feature states with scaled \n",
    "##    parameter values\n",
    "\n",
    "u_sigma = np.empty((0,1),)\n",
    "u_shift_sigma = np.empty((0,1),)\n",
    "\n",
    "p_max = np.asarray(param_list).max()\n",
    "for indx,val in enumerate(param_list/p_max):\n",
    "    u_sigma = np.vstack((u_sigma,val*np.ones((Nt_train[indx],1))))\n",
    "    u_shift_sigma = np.vstack((u_shift_sigma,val*np.ones((Nt_train[indx],1)) ))\n",
    "    \n",
    "u = np.hstack(( u,u_sigma))\n",
    "u_shift = np.hstack(( u_shift, u_shift_sigma))\n",
    "\n",
    "\n",
    "if validation_data:\n",
    "    u_val_sigma = np.empty((0,1),)\n",
    "    u_val_shift_sigma = np.empty((0,1),)\n",
    "    for indx,val in enumerate(param_list/p_max):\n",
    "        val_steps = np.minimum(times_offline[indx][skip_start:snap_end[indx]+1:snap_incr].size, Nt_train[indx])\n",
    "        u_val_sigma = np.vstack((u_val_sigma, val*np.ones((val_steps,1)) ))\n",
    "        u_val_shift_sigma = np.vstack((u_val_shift_sigma, val*np.ones((val_steps,1)) ))\n",
    "        \n",
    "        \n",
    "u_val = np.hstack(( u_val, u_val_sigma))\n",
    "u_val_shift = np.hstack(( u_val_shift, u_val_shift_sigma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c9d576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:18.787656Z",
     "start_time": "2022-02-14T03:40:18.150092Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Define minibatch generators for training and\n",
    "## validation using Tensorflow Dataset API\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "size_buffer = max(list(Nt_train.values()))\n",
    "# if flag == 'sigma':\n",
    "#     size_buffer = Nt_train[0]\n",
    "# elif flag == 'speed':\n",
    "#     size_buffer = sum(list(Nt_train.values()))\n",
    "    \n",
    "u_train, u_val = tu.gen_batch_ae(u, u_shift, u_val, u_val_shift, \n",
    "                                 batch_size=batch_size, shuffle_buffer=size_buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0cfb14e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T03:40:22.530599Z",
     "start_time": "2022-02-14T03:40:22.525021Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100702    629    251     62]\n",
      "Output Size of Encoder Input Layer = 629\n"
     ]
    }
   ],
   "source": [
    "# class AAautoencoder(tf.keras.models.Model):\n",
    "#     def __init__(self, latent_dim, act, size, **kwargs):\n",
    "#         super(AAautoencoder, self).__init__(**kwargs)\n",
    "        \n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.activation = act\n",
    "#         self.hidden_units = size\n",
    "#         try:\n",
    "#             self.l2_lam = kwargs['l2_lam']\n",
    "#         except:\n",
    "#             self.l2_lam = 1e-6\n",
    "        \n",
    "#         self.encoder = Sequential()\n",
    "#         self.encoder.add(InputLayer(input_shape=(size[0],), name='Field'))\n",
    "#         self.encoder.add(Dense(size[1], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.encoder.add(Dense(size[2], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.encoder.add(Dense(size[3], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.encoder.add(Dense(latent_dim, activation='linear'))\n",
    "    \n",
    "        \n",
    "#         self.shift = Sequential()\n",
    "#         self.shift.add(Dense(size[3], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.shift.add(Dense(size[2], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.shift.add(Dense(size[1], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.shift.add(Dense(size[0], activation='linear',kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "        \n",
    "        \n",
    "#         self.decoder = Sequential()\n",
    "#         self.decoder.add(Dense(size[3], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.decoder.add(Dense(size[2], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.decoder.add(Dense(size[1], activation=act,kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "#         self.decoder.add(Dense(size[0], activation='linear',kernel_regularizer=regularizers.l2(self.l2_lam)))\n",
    "\n",
    "#     def call(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         decoded = self.decoder(encoded)\n",
    "#         return decoded\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         return {\"hidden_units\": self.hidden_units, \n",
    "#                 \"activation\": self.activation, \n",
    "#                 \"latent_dim\": self.latent_dim}\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_config(cls, config):\n",
    "#         return cls(**config)\n",
    "\n",
    "\n",
    "size0 = u.shape[1]\n",
    "size1 = int(np.floor(size0//160))\n",
    "size2 = int(np.floor(size0//400))\n",
    "size3 = int(np.floor(size0//1600))\n",
    "\n",
    "\n",
    "size = np.array([size0, size1, size2, size3])\n",
    "print(size)\n",
    "\n",
    "latent_dim_u = 15\n",
    "\n",
    "print('Output Size of Encoder Input Layer = %d'%size1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b317c289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T04:15:08.607002Z",
     "start_time": "2022-02-14T04:15:08.585179Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "## Custom training loop for AA Autoencoder model\n",
    "\n",
    "os.chdir(nn_dir)\n",
    "reload(aa)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "def train_AAautoencoder(epochs, train_dataset, val_dataset, latent_dim, actvn, size, Nt, **kwargs):\n",
    "    \n",
    "    loss_wt = kwargs['loss_weights']\n",
    "    model = aa.AAautoencoder(latent_dim, actvn, size,)\n",
    "    \n",
    "            \n",
    "    try:\n",
    "        learn_rate = kwargs['lr']\n",
    "    except:\n",
    "        learn_rate = 0.0001\n",
    "    try:\n",
    "        batch_size = kwargs['batch_size']\n",
    "    except:\n",
    "        batch_size = 64\n",
    "    try:\n",
    "        reg_wt = kwargs['reg']\n",
    "    except:\n",
    "        reg_wt = 0.02\n",
    "        \n",
    "    try:\n",
    "        lb = kwargs['loss_lb']\n",
    "    except:\n",
    "        lb = 0.9\n",
    "        \n",
    "    try:\n",
    "        decay_factor = kwargs['decay'][0]; decay_rate = kwargs['decay'][1]\n",
    "    except:\n",
    "        decay_factor = 15; decay_rate = 0.9\n",
    "    \n",
    "    try: \n",
    "        learning_rate_decay = kwargs['lr_decay']\n",
    "        init_learn_rate = tf.keras.optimizers.schedules.ExponentialDecay(learn_rate, \n",
    "                                                        decay_steps=epochs*Nt//batch_size//decay_factor,\n",
    "                                                        decay_rate=decay_rate, staircase=True)\n",
    "    except:\n",
    "        init_learn_rate = learn_rate\n",
    "        \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=init_learn_rate)\n",
    "    \n",
    "\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    shift_loss = []\n",
    "    recon_loss = []\n",
    "    lr = []\n",
    "    regu_loss = []\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        train_loss_value = 0; \n",
    "        shift_loss_value = 0; \n",
    "        recon_loss_value = 0;\n",
    "        rloss_value = 0\n",
    "        for step_train, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "            # Open a GradientTape to record the operations run\n",
    "            # during the forward pass, which enables auto-differentiation.\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                # Run the forward pass of the layer.\n",
    "              \n",
    "                \n",
    "                ## Encoded output for this minibatch\n",
    "                encoded = model.encoder(x_batch_train, training=True)\n",
    "                \n",
    "                ## Shift Decoder Evaluation for this minibatch\n",
    "                pred = model.shift(encoded, training=True)  \n",
    "                \n",
    "                ## True Decoder Evaluation for this minibatch\n",
    "                recon = model.decoder(encoded, training=True)\n",
    "                \n",
    "                ## L2 Regularization Loss Component\n",
    "                l2_loss=tf.add_n(model.losses)\n",
    "                \n",
    "                ## Compute the loss value for this minibatch.\n",
    "                loss1 = tu.comb_loss(y_batch_train[:,:], pred, lb=lb, delta=0.5) #\\\n",
    "                loss2 = tu.comb_loss(x_batch_train[:,:], recon, lb=lb, delta=0.5) #\\\n",
    "\n",
    "                if epoch < kwargs['segmented']:\n",
    "                    loss_value = loss_wt[0] * loss1 + loss_wt[1] * loss2 \n",
    "                else:\n",
    "                    loss_value = loss_wt[2] * loss1 + loss_wt[3] * loss2\n",
    "                \n",
    "                reg_loss = reg_wt*tf.sqrt(l2_loss)/(epoch+1)\n",
    "                loss_value += reg_loss\n",
    "                rloss_value +=reg_loss\n",
    "                       \n",
    "            train_loss_value += loss_value\n",
    "            shift_loss_value += loss1\n",
    "            recon_loss_value += loss2\n",
    "            \n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables,\n",
    "                        unconnected_gradients=tf.UnconnectedGradients.ZERO) \n",
    "            ## Suppress warnings about zero gradients during training\n",
    "            \n",
    "            # Run one step of gradient descent by updating\n",
    "            # the value of the variables to minimize the loss.\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            # Log every 10 batches.\n",
    "            if step_train % 10 == 0:\n",
    "                print(\"Training loss for batch %d: Shift: %.4e, Recon: %.4e, Reg: %.4e\"\n",
    "                    % ((step_train+1), float(loss1), float(loss2), float(reg_loss)))\n",
    "                print(\"Seen so far: %s samples\" % ((step_train + 1) * batch_size))\n",
    "                \n",
    "        train_loss.append((train_loss_value/(step_train + 1)).numpy())\n",
    "        shift_loss.append((shift_loss_value/(step_train + 1)).numpy())\n",
    "        recon_loss.append((recon_loss_value/(step_train + 1)).numpy())\n",
    "        regu_loss.append((rloss_value/(step_train + 1)).numpy())\n",
    "        \n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        val_loss_value = 0; \n",
    "        for step_val, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
    "            \n",
    "            encoded_val = model.encoder(x_batch_val, training=False)\n",
    "            pred_val = model.shift(encoded_val, training=False)\n",
    "            recon_val = model.decoder(encoded_val, training=False)\n",
    "            \n",
    "            loss_val1 = tu.comb_loss(y_batch_val[:,:], pred_val, lb=lb,delta=0.5) #\\\n",
    "            loss_val2 = tu.comb_loss(x_batch_val[:,:], recon_val, lb=lb,delta=0.5) #\\\n",
    "            \n",
    "            if epoch < kwargs['segmented']:\n",
    "                val_loss_value += loss_wt[0] * loss_val1 + loss_wt[1] * loss_val2 \n",
    "            else:\n",
    "                val_loss_value += loss_wt[2] * loss_val1 + loss_wt[3] * loss_val2\n",
    "        \n",
    "        val_loss_value += rloss_value\n",
    "        val_loss.append((val_loss_value/(step_val+1)).numpy())\n",
    "        \n",
    "        if learning_rate_decay:\n",
    "            print(\"Epoch %d, Training Loss: %.4e, Validation Loss: %.4e. LR: %.4e\" \n",
    "                  % (epoch, float(train_loss[-1]),float(val_loss[-1]),init_learn_rate(optimizer.iterations).numpy()))\n",
    "            lr.append(init_learn_rate(optimizer.iterations).numpy())\n",
    "        else:\n",
    "            print(\"Epoch %d, Training Loss: %.4e, Validation Loss: %.4e. LR: %.4e\" \n",
    "                  % (epoch, float(train_loss[-1]),float(val_loss[-1]),learn_rate))\n",
    "            lr.append(learn_rate)\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"****Total training time = {0}****\\n\".format(end_time - start_time))\n",
    "    \n",
    "    return model, train_loss, val_loss, shift_loss, recon_loss, lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "499ffcb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T04:15:09.357809Z",
     "start_time": "2022-02-14T04:15:09.353724Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Load AE model\n",
    "\n",
    "load_ae_model = False\n",
    "\n",
    "if load_ae_model:\n",
    "    pre_trained_dir = '/gpfs/cwfs/sdutta/ae_data/pulse/ae_shift_inv_comb_models/saved_model_AA1'\n",
    "    mnum = pre_trained_dir.split('saved_model_')[1]\n",
    "\n",
    "    ## When using custom loss functions while training, there are two ways\n",
    "    ## to load a saved model\n",
    "    ## 1) If loaded model will not be used for retraining, then\n",
    "    ##   use 'compile=False' option while loading so that TF does\n",
    "    ##   search for loss functions\n",
    "    u_autoencoder = tf.keras.models.load_model(pre_trained_dir+'/u_autoenc',compile=False)\n",
    "\n",
    "    ae_training = np.load(pre_trained_dir+'/model_history_%s.npz'%mnum)\n",
    "\n",
    "    print(ae_training['msg'])\n",
    "\n",
    "    loss_u = ae_training['loss']\n",
    "    vloss_u = ae_training['valloss'] \n",
    "    sloss_u = ae_training['shiftloss'] \n",
    "    rloss_u = ae_training['reconloss'] \n",
    "    lr_u = ae_training['lr']\n",
    "    epochs_u = ae_training['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e559a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T04:15:10.226797Z",
     "start_time": "2022-02-14T04:15:10.180883Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'regu')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-267750a43a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sigma'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         u_autoencoder, loss_u, vloss_u, sloss_u, rloss_u, lr_u = train_AAautoencoder(5, u_train, u_val, \n\u001b[0m\u001b[1;32m     16\u001b[0m                                                               \u001b[0mlatent_dim_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactvn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                               \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNt_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-da57ccd4cee9>\u001b[0m in \u001b[0;36mtrain_AAautoencoder\u001b[0;34m(epochs, train_dataset, val_dataset, latent_dim, actvn, size, Nt, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss_wt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAAautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactvn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/erdc/aa_autoencoder_mca/src/nn_model/aa_autoencoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, latent_dim, act, hidden_dim, name, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/erdc/aa_autoencoder_mca/src/nn_model/aa_autoencoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, latent_dim, act, hidden_dim, name, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"encoder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pynirom/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pynirom/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     }\n\u001b[1;32m    339\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pynirom/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    806\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'regu')"
     ]
    }
   ],
   "source": [
    "## Training the AA Autoencoder Model\n",
    "actvn = tf.keras.activations.swish ## 'swish' activation\n",
    "\n",
    "if not load_ae_model:\n",
    "    if flag == 'speed':\n",
    "        u_autoencoder, loss_u, vloss_u, sloss_u, rloss_u, lr_u = train_AAautoencoder(epochs_u, u_train, u_val, \n",
    "                                                  latent_dim_u, actvn, np.aaray([size[0], size[2], size[3]]),\n",
    "                                                  sum(list(Nt_train.values())),\n",
    "                                                  batch_size = batch_size, loss_lb = 0.9,\n",
    "                                                  segmented = 2500, decay = [15, 0.9],\n",
    "                                                  loss_weights = [0.1, 0.88, 0.49, 0.49],\n",
    "                                                  lr = 1e-4, lr_decay = True, reg = 0.02 )\n",
    "\n",
    "    if flag == 'sigma':\n",
    "        u_autoencoder, loss_u, vloss_u, sloss_u, rloss_u, lr_u = train_AAautoencoder(5, u_train, u_val, \n",
    "                                                              latent_dim_u, actvn, size,  \n",
    "                                                              sum(list(Nt_train.values())),\n",
    "                                                              batch_size = batch_size, loss_lb = 0.9,\n",
    "                                                              segmented = 2500, decay = [17, 0.85],\n",
    "                                                              loss_weights = [0.0, 0.98, 0.1, 0.88],\n",
    "                                                              lr = 5e-4, lr_decay = True, reg = 0.02 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063607f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T23:48:45.400707Z",
     "start_time": "2022-02-12T23:48:45.381238Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "u_autoencoder.encoder.summary()\n",
    "u_autoencoder.shift.summary()\n",
    "u_autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf566a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T23:48:48.114608Z",
     "start_time": "2022-02-12T23:48:45.403765Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_u = u_autoencoder.encoder(u).numpy()\n",
    "shift_u = u_autoencoder.shift(encoded_u).numpy()\n",
    "decoded_u = u_autoencoder.decoder(encoded_u).numpy()\n",
    "\n",
    "encoded = encoded_u\n",
    "\n",
    "\n",
    "print('\\n*********AE shifted decoder reconstruction error*********\\n')\n",
    "print('u  Shift MSE: ' + str(np.mean(np.square(du.scaler_inverse(shift_u[:,:-1], u_max, u_min, scaling=scaling)-du.scaler_inverse(u_shift[:,:-1], u_max, u_min, scaling=scaling)))))\n",
    "\n",
    "print('\\n*********AE inverse decoder reconstruction error*********\\n')\n",
    "print('u  Reconstruction MSE: ' + str(np.mean(np.square(du.scaler_inverse(decoded_u[:,:-1], u_max, u_min, scaling=scaling)-du.scaler_inverse(u[:,:-1], u_max, u_min, scaling=scaling)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe6c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T23:48:48.120804Z",
     "start_time": "2022-02-12T23:48:48.115941Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Save the trained AE model\n",
    "\n",
    "save_ae_model = False\n",
    "    \n",
    "if save_ae_model:\n",
    "    \n",
    "    !mkdir -p /gpfs/cwfs/sdutta/ae_data/pulse/ae_shift_inv_comb_models/saved_model_AA1\n",
    "    \n",
    "    savedir = data_dir+'/gpfs/cwfs/sdutta/ae_data/pulse/ae_shift_inv_comb_models/saved_model_AA1'\n",
    "    mnum = savedir.split('saved_model_')[1]\n",
    "    \n",
    "    ## To use TF SavedModel format with a custom training loop,\n",
    "    ## call model.predict() on some input tensors first.\n",
    "    ## Otherwise TF doesn't know the shape and dtype of input data\n",
    "    ## it should be expecting, and thus cannot create it's weight \n",
    "    ## variables. When using model.fit() this step happens automatically.\n",
    "    test_predict = u_autoencoder.predict(u)\n",
    "    \n",
    "    u_autoencoder.save(savedir+'/u_autoenc')\n",
    "    msg = 'Sigma = [5,10,20], speed = [1],'\\\n",
    "    +'Trains both shift and reconstruction decoder,'\\\n",
    "    +'\\nStep decay LR scheduler starting from 1e-4, Batch Size = 24,'\\\n",
    "    +'\\nDecaying 10% every 96 epochs,'\\\n",
    "    +'\\nFor epochs <=2500: Loss = 0.10*Shift + 0.88*True,'\\\n",
    "    +'\\nFor epochs > 2500: Loss = 0.49*Shift + 0.49*True,'\\\n",
    "    +'\\n90% NMSE + 10% Huber, L2 regularization, Scaling to [0,1],'\\\n",
    "    +'\\nBoth Encoder input & Decoder ouput are augmented by parameter value'\n",
    "    print(\"\\n===========\")\n",
    "    print(msg)\n",
    "    \n",
    "\n",
    "    np.savez_compressed(savedir+'/model_history_%s'%mnum, \n",
    "                        loss = loss_u, valloss = vloss_u, \n",
    "                        shiftloss = sloss_u, reconloss = rloss_u,\n",
    "                        lr = lr_u, epochs = epochs_u, \n",
    "                        msg=msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b151d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T23:48:48.777559Z",
     "start_time": "2022-02-12T23:48:48.122049Z"
    },
    "code_folding": [
     2
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_num = 0\n",
    "\n",
    "def select_variable(param_num):\n",
    "    p_indx = sum(list(Nt_train.values())[:param_num]); \n",
    "    encoded = encoded_u[p_indx:p_indx+Nt_train[param_num]]; ldim = latent_dim_u\n",
    "    return encoded, ldim\n",
    "\n",
    "def plot_latent_param_nums(param_num):\n",
    "\n",
    "    num_rows = 5 #np.maximum(4, encoded.shape[1]//4)\n",
    "    fig, ax = plt.subplots(nrows=num_rows,ncols=1,figsize=(6,num_rows*1.75),constrained_layout=True)    \n",
    "\n",
    "    for ix,comp in enumerate([param_num]):\n",
    "        encoded, ldim = select_variable(comp)\n",
    "        \n",
    "        for i in range(num_rows):\n",
    "            tt = ax[i].plot(times_offline[comp][:snap_end[comp]+1:snap_incr],encoded[:,i],label='mode %d'%i,marker='o',markevery=20)\n",
    "            ax[i].legend()\n",
    "        ax[i].set_xlabel('Time')  \n",
    "        fig.suptitle('AE modes for %s = %.2f'%(flag, param_list[param_num]),fontsize=16)  \n",
    "\n",
    "\n",
    "plot_latent_param_nums(param_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7c88f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T23:48:49.209431Z",
     "start_time": "2022-02-12T23:48:48.778775Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Visualization losses and learning rate evolution\n",
    "num_epochs_u = np.arange(epochs_u)\n",
    "\n",
    "pu.plot_training(num_epochs_u, loss_u, vloss_u, lr_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05838696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-12T23:48:49.713327Z",
     "start_time": "2022-02-12T23:48:49.210597Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(8,4),constrained_layout=True)\n",
    "ax.semilogy(num_epochs_u, sloss_u,'b-.',label='u:shift_loss')\n",
    "ax.semilogy(num_epochs_u, rloss_u,'k--',label='u:recon_loss')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52977c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:27:28.006379Z",
     "start_time": "2022-02-13T00:27:26.181048Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Predict using all high-fidelity data points \n",
    "### for parameter values in the training set\n",
    "\n",
    "iparam = np.random.choice(len(param_list))\n",
    "print(\"Testing AE predictions for %s = %f (parameter number = %d)\"%(flag,param_list[iparam], iparam))\n",
    "val = param_list[iparam]/p_max\n",
    "\n",
    "u_test = np.hstack(( snap_data[iparam]['pulse'][:,:snap_end[iparam]+1].T, val*np.ones((Nt[iparam],1)) ))\n",
    "u_shift_test = np.hstack(( shifted_snap[iparam]['pulse'][:,:snap_end[iparam]+1].T, val*np.ones((Nt[iparam],1)) ))\n",
    "\n",
    "if scaling:\n",
    "    u_test, u_shift_test, _, _ = du.data_scaler(u_test, u_shift_test, u_max, u_min)\n",
    "\n",
    "\n",
    "encoded_u_test = u_autoencoder.encoder(u_test).numpy()\n",
    "shift_u_test = u_autoencoder.shift(encoded_u_test).numpy()\n",
    "recon_u_test = u_autoencoder.decoder(encoded_u_test).numpy()\n",
    "\n",
    "pred_shift = {}\n",
    "pred_shift['pulse'] = du.scaler_inverse(shift_u_test[:,:-1], u_max, u_min, scaling=scaling).T\n",
    "\n",
    "pred_recon = {}\n",
    "pred_recon['pulse'] = du.scaler_inverse(recon_u_test[:,:-1], u_max, u_min, scaling=scaling).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418ffc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:27:28.493605Z",
     "start_time": "2022-02-13T00:27:28.008105Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Visualizing reconstruction of shifted snapshots using shift decoder  \n",
    "    \n",
    "fig = plt.figure(figsize=(14,8))\n",
    "ky = 'pulse'; \n",
    "np.random.seed(2021)\n",
    "iplot = 80 \n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.82)\n",
    "\n",
    "pu.compare_soln(pred_shift,shifted_snap[iparam],iplot,times_offline[iparam],times_offline[iparam],Nx,Ny,ky,flag='AE')\n",
    "fig.suptitle(\"Comparing AE predictions of shifted snapshots \\nfor %s = %d at t = %.2f mins\"%(flag, param_list[iparam], times_offline[iparam][iplot]/60),fontsize=18, y=0.98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866ea17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:27:28.839957Z",
     "start_time": "2022-02-13T00:27:28.495203Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Visualizing direct reconstruction using true decoder\n",
    "\n",
    "fig = plt.figure(figsize=(14,8))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.82)\n",
    "\n",
    "pu.compare_soln(pred_recon,snap_data[iparam],iplot,times_offline[iparam],times_offline[iparam],Nx,Ny,ky,flag='AE')\n",
    "fig.suptitle(\"Comparing AE predictions of true snapshots \\nfor %s = %d at t = %.2f mins\"%(flag, param_list[iparam], times_offline[iparam][iplot]/60),fontsize=18, y=0.98)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb01b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:27:29.881319Z",
     "start_time": "2022-02-13T00:27:28.841234Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Compute rel error for decoded prediction of shifted and true solutions\n",
    "rel_err_shift = {}\n",
    "rel_err_recon = {}\n",
    "\n",
    "for key in soln_names:\n",
    "    true = shifted_snap[iparam][key][:,:snap_end[iparam]+1]\n",
    "    true2 = snap_data[iparam][key][:,:snap_end[iparam]+1]\n",
    "    rel_err_shift[key] = np.linalg.norm(pred_shift[key][:,:]-true,axis=0)/np.linalg.norm(true,axis=0)\n",
    "    rel_err_recon[key] = np.linalg.norm(pred_recon[key][:,:]-true2,axis=0)/np.linalg.norm(true2,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d14507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:27:30.186287Z",
     "start_time": "2022-02-13T00:27:29.882853Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Visualize relative errors for both decoders\n",
    "\n",
    "fig = plt.figure(figsize=(16,5))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85)\n",
    "indx = times_offline[iparam][:snap_end[iparam]+1]/60\n",
    "val_mark = int(times_offline[iparam][:snap_end[iparam]+1].size*1.0)-30\n",
    "    \n",
    "if validation_data:\n",
    "    val_skip = 2\n",
    "else:\n",
    "    val_skip = 1\n",
    "\n",
    "val_dict = {'v_data': validation_data, 'v_mark': val_mark, 'v_skip': val_skip, 'legend': True}\n",
    "pu.plot_rel_err(indx,rel_err_shift,rel_err_recon,val_dict, ky='pulse')\n",
    "fig.suptitle('Relative errors of AE prediction for speed = %d'%(c[iparam]),fontsize=18, y=0.98)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6dec26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:27:57.818607Z",
     "start_time": "2022-02-13T00:27:53.386806Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Evaluate predictions on a dataset with unseen parameter value\n",
    "\n",
    "new_test = True\n",
    "\n",
    "if new_test:\n",
    "    if flag == 'speed':\n",
    "        test_param = np.random.choice([5,6,8])\n",
    "        c_new = test_param; sigma_new = 8\n",
    "        new_data = np.load(os.path.join(data_dir,'Gaussian2d_pulse_500x200_c%.2f_sigma5.0000.npz'%c_new))\n",
    "        \n",
    "    elif flag == 'sigma':\n",
    "        test_param = np.random.choice([ 8, 16])  #3.3333, 4,\n",
    "        c_new = 1; sigma_new = test_param\n",
    "        new_data = np.load(os.path.join(data_dir,'Gaussian2d_pulse_500x200_c1.00_sigma%.4f.npz'%sigma_new))\n",
    "        \n",
    "    \n",
    "    print(\"Chosen parameter: %s = %f\"%(flag, test_param))\n",
    "    print(\"Loading pre-computed true snapshots -----\\n\")\n",
    "    \n",
    "    snap_new, times_new, nodes2, Nx2, Ny2, snap_start_new, snap_end_new = du.read_data(new_data, soln_names)\n",
    "    Nt_new = times_new.size\n",
    "\n",
    "    \n",
    "    if flag == 'speed':\n",
    "        new_shift_data = np.load(os.path.join(data_dir,'Shift_Gaussian2d_pulse_500x200_c%.2f_sigma5.0000.npz'%c_new))\n",
    "    elif flag == 'sigma':\n",
    "        new_shift_data = np.load(os.path.join(data_dir,'Shift_Gaussian2d_pulse_500x200_c1.00_sigma%.4f.npz'%sigma_new))\n",
    "    \n",
    "    print(\"Loading pre-computed shifted snapshots -----\\n\")\n",
    "\n",
    "    shifted_snap_new = {}\n",
    "    for key in soln_names:\n",
    "        tmp = new_shift_data[key].reshape((Nn,-1))\n",
    "        shifted_snap_new[key] = np.outer(tmp,np.ones(Nt_new))\n",
    "\n",
    "    del new_data\n",
    "    del new_shift_data\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    u_new = snap_new['pulse'][:,:snap_end_new+1].T\n",
    "    u_shift_new = shifted_snap_new['pulse'][:,:snap_end_new+1].T\n",
    "    \n",
    "    u_new = np.hstack(( u_new, (test_param/p_max)*np.ones((Nt_new,1)) ))\n",
    "    u_shift_new = np.hstack(( u_shift_new, (test_param/p_max)*np.ones((Nt_new,1)) ))\n",
    "\n",
    "    if scaling:\n",
    "        u_new, u_shift_new, _, _ = du.data_scaler(u_new, u_shift_new, u_max, u_min)\n",
    "\n",
    "    encoded_u_new = u_autoencoder.encoder(u_new).numpy()\n",
    "    shift_u_new = u_autoencoder.shift(encoded_u_new).numpy()\n",
    "    recon_u_new = u_autoencoder.decoder(encoded_u_new).numpy()\n",
    "\n",
    "\n",
    "    pred_shift_new = {}\n",
    "    pred_shift_new['pulse'] = du.scaler_inverse(shift_u_new[:,:-1], u_max, u_min, scaling=scaling).T\n",
    "\n",
    "    pred_recon_new = {}\n",
    "    pred_recon_new['pulse'] = du.scaler_inverse(recon_u_new[:,:-1], u_max, u_min, scaling=scaling).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25d512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:30:47.062218Z",
     "start_time": "2022-02-13T00:30:46.426869Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Visualizing reconstruction of shifted snapshots using shift decoder\n",
    "if new_test:\n",
    "    fig = plt.figure(figsize=(14,8))\n",
    "    ky = 'pulse'; iplot = 40 #np.random.choice(times_new.size)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.82)\n",
    "    pu.compare_soln(pred_shift_new,shifted_snap_new,iplot,times_new,times_new,Nx,Ny,ky,flag='AE')\n",
    "    fig.suptitle(\"Comparing AE predictions of shifted snapshots \\nfor %s = %.2f at t = %.2f mins\"%(flag, test_param, times_new[iplot]/60),fontsize=18, y=0.98)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05632c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:30:49.685595Z",
     "start_time": "2022-02-13T00:30:49.064176Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Visualizing direct reconstruction using true decoder\n",
    "if new_test:\n",
    "    fig = plt.figure(figsize=(14,8))\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.82)\n",
    "    pu.compare_soln(pred_recon_new,snap_new,iplot,times_new,times_new,Nx,Ny,ky,flag='AE')\n",
    "    fig.suptitle(\"Comparing AE predictions of true snapshots \\nfor %s = %.2f at t = %.2f mins\"%(flag, test_param, times_new[iplot]/60),fontsize=18, y=0.98)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0719b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:28:14.063299Z",
     "start_time": "2022-02-13T00:28:12.861285Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if new_test:\n",
    "    ## Compute rel error for decoded prediction of shifted solutions\n",
    "    rel_err_shift_new = {}\n",
    "    rel_err_recon_new = {}\n",
    "\n",
    "    for key in soln_names:\n",
    "        true_new = shifted_snap_new[key][:,:snap_end_new+1]\n",
    "        true2_new = snap_new[key][:,:snap_end_new+1]\n",
    "        rel_err_shift_new[key] = np.linalg.norm(pred_shift_new[key][:,:]-true_new,axis=0)/np.linalg.norm(true_new,axis=0)\n",
    "        rel_err_recon_new[key] = np.linalg.norm(pred_recon_new[key][:,:]-true2_new,axis=0)/np.linalg.norm(true2_new,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcd2ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T00:28:19.984163Z",
     "start_time": "2022-02-13T00:28:19.577994Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if new_test:\n",
    "    ### Visualize relative errors for both decoders\n",
    "\n",
    "    fig = plt.figure(figsize=(16,5))\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    indx = times_new[:snap_end_new+1]/60\n",
    "\n",
    "    val_dict_new = {'v_data': False, 'v_mark': indx.size, 'v_skip': 1, 'legend': False}\n",
    "    pu.plot_rel_err(indx, rel_err_shift_new, rel_err_recon_new, val_dict_new, ky='pulse')\n",
    "    fig.suptitle('Relative errors of AE prediction for speed = %d'%(c_new),fontsize=18, y=0.98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596a0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
